"""
è¯­ä¹‰æ ‡ç­¾ç”Ÿæˆæ¨¡å— - ä½¿ç”¨ LLM ä¸ºæ­Œæ›²æ‰“æ ‡ç­¾
"""

import re
import json
import time
import sys
import requests
import logging
from typing import Optional, Tuple, Dict, Any

from config.settings import NAV_DB, SEM_DB, API_KEY, BASE_URL, MODEL, LOG_DIR, API_PROVIDER, API_CONFIG
from config.constants import ALLOWED_LABELS, PROMPT_TEMPLATE
from src.core.database import connect_nav_db, connect_sem_db
from src.core.schema import init_semantic_db
from src.utils.logger import setup_logger

# è®¾ç½®æ—¥å¿—
logger = setup_logger('tagging', 'semantic_processing.log', level=logging.DEBUG)


def safe_extract_json(text: str) -> Optional[Dict[str, Any]]:
    """
    ä» LLM å“åº”ä¸­æå– JSONï¼Œæ”¯æŒå¤„ç†æˆªæ–­è¡¥é½å’Œ Markdown ä»£ç å—
    
    Args:
        text: LLM è¿”å›çš„åŸå§‹æ–‡æœ¬
        
    Returns:
        è§£æåçš„ JSON å­—å…¸ï¼Œå¦‚æœè§£æå¤±è´¥åˆ™è¿”å› None
        
    å¤„ç†é€»è¾‘:
        1. ç§»é™¤ Markdown ä»£ç å—æ ‡è®° (```json ... ```)
        2. æŸ¥æ‰¾æ‰€æœ‰ JSON å¯¹è±¡
        3. å–æœ€åä¸€ä¸ªåŒ¹é…ï¼ˆåº”å¯¹ Reasoning æ¨¡å‹ï¼‰
        4. å¦‚æœ JSON è¢«æˆªæ–­ï¼Œå°è¯•è¡¥é½
    """
    try:
        # ç§»é™¤ markdown ä»£ç å—
        clean_text = re.sub(r"```json\s*|\s*```", "", text).strip()
        # å¯»æ‰¾ JSON å¯¹è±¡
        matches = re.findall(r"\{.*\}", clean_text, re.S)
        if matches:
            return json.loads(matches[-1])  # å–æœ€åä¸€ä¸ªï¼Œåº”å¯¹ Reasoning æ¨¡å‹

        # é’ˆå¯¹æˆªæ–­çš„ä¿åº•å°è¯•
        if clean_text.startswith("{") and not clean_text.endswith("}"):
            fixed = clean_text + '"}'
            return json.loads(fixed)
    except (json.JSONDecodeError, ValueError, AttributeError) as e:
        # è®°å½•å…·ä½“çš„é”™è¯¯ç±»å‹ï¼Œä¾¿äºè°ƒè¯•
        return None


def nim_classify(title: str, artist: str, album: str) -> Tuple[Optional[Dict[str, Any]], str]:
    """
    è°ƒç”¨ LLM API ä¸ºæ­Œæ›²ç”Ÿæˆè¯­ä¹‰æ ‡ç­¾ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
    
    Args:
        title: æ­Œæ›²æ ‡é¢˜
        artist: æ­Œæ‰‹åç§°
        album: ä¸“è¾‘åç§°
        
    Returns:
        Tuple[Optional[Dict[str, Any]], str]:
            - è§£æåçš„æ ‡ç­¾å­—å…¸ï¼ˆåŒ…å« mood, energy, scene, region, subculture, genre, confidenceï¼‰
            - åŸå§‹ API å“åº”å†…å®¹
            
    Raises:
        requests.HTTPError: API è¯·æ±‚å¤±è´¥ä¸”é‡è¯•æ¬¡æ•°ç”¨å°½æ—¶æŠ›å‡º
    """
    # æ ¹æ®é…ç½®çš„æä¾›å•†ç”Ÿæˆå¯¹åº”çš„æç¤ºè¯æ¨¡æ¿
    prompt_template = PROMPT_TEMPLATE
    prompt = prompt_template.format(
        title=title, artist=artist, album=album
    )

    headers = {"Authorization": f"Bearer {API_KEY}", "Content-Type": "application/json"}
    payload = {
        "model": MODEL,
        "messages": [{"role": "user", "content": prompt}],
        "temperature": API_CONFIG["temperature"],
        "max_tokens": API_CONFIG["max_tokens"]
    }

    max_retries = API_CONFIG["max_retries"]
    retry_delay = API_CONFIG["retry_delay"]
    retry_backoff = API_CONFIG["retry_backoff"]

    for attempt in range(max_retries):
        try:
            r = requests.post(BASE_URL, headers=headers, json=payload, timeout=API_CONFIG["timeout"])
            r.raise_for_status()
            content = r.json()['choices'][0]['message']['content']
            return safe_extract_json(content), content
        except requests.exceptions.RequestException as e:
            if attempt < max_retries - 1:
                # è®¡ç®—é€€é¿å»¶è¿Ÿæ—¶é—´
                delay = retry_delay * (retry_backoff ** attempt)
                logger.warning(f"API è¯·æ±‚å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}, {delay}ç§’åé‡è¯•...")
                time.sleep(delay)
            else:
                logger.error(f"API è¯·æ±‚å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({max_retries}): {e}")
                raise


def normalize(field: str, value: Any) -> str:
    """
    è§„èŒƒåŒ–æ ‡ç­¾å€¼ï¼Œç¡®ä¿æ ‡ç­¾åœ¨ç™½åå•ä¸­
    
    Args:
        field: æ ‡ç­¾å­—æ®µåï¼ˆå¦‚ 'mood', 'energy' ç­‰ï¼‰
        value: åŸå§‹æ ‡ç­¾å€¼
        
    Returns:
        è§„èŒƒåŒ–åçš„æ ‡ç­¾å€¼ï¼Œå¦‚æœä¸åœ¨ç™½åå•ä¸­åˆ™è¿”å› 'None'
    """
    if not value:
        return "None"
    val_str = str(value).strip().lower()
    lookup = {v.lower(): v for v in ALLOWED_LABELS[field]}
    return lookup.get(val_str, "None")


def format_time(seconds: float) -> str:
    """
    æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤ºä¸º HH:MM:SS æ ¼å¼
    
    Args:
        seconds: ç§’æ•°
        
    Returns:
        æ ¼å¼åŒ–åçš„æ—¶é—´å­—ç¬¦ä¸²ï¼Œå¦‚ "01:23:45"
    """
    m, s = divmod(int(seconds), 60)
    h, m = divmod(m, 60)
    return f"{h:02d}:{m:02d}:{s:02d}"


def main() -> None:
    """ä¸»å‡½æ•° - å¤„ç†æ‰€æœ‰æœªæ‰“æ ‡ç­¾çš„æ­Œæ›²"""
    nav = connect_nav_db()
    sem = connect_sem_db()

    # åˆå§‹åŒ–è¡¨ç»“æ„
    init_semantic_db(sem)

    # è·å–è¿›åº¦
    done_ids = {row['file_id'] for row in sem.execute("SELECT file_id FROM music_semantic").fetchall()}
    all_songs = nav.execute("SELECT id, title, artist, album FROM media_file").fetchall()
    todo = [s for s in all_songs if str(s['id']) not in done_ids]

    total = len(todo)
    if total == 0:
        logger.info("âœ… All songs processed.")
        return

    logger.info(f"ğŸµ Processing {total} new songs. (Total in Library: {len(all_songs)})")
    start_time = time.time()
    success = 0

    # å¾ªç¯å¤„ç†å¹¶è®°å½•æ—¥å¿—
    for idx, s in enumerate(todo, 1):
        meta = f"{s['artist']} - {s['title']}"
        try:
            t0 = time.time()
            # è·å–ç»“æœ
            res, raw_content = nim_classify(s["title"], s["artist"], s["album"])
            elapsed = time.time() - t0

            if not res:
                raise ValueError("Failed to parse JSON from AI response")

            # è§„èŒƒåŒ–
            mood = normalize("mood", res.get("mood"))
            energy = normalize("energy", res.get("energy"))
            scene = normalize("scene", res.get("scene"))
            region = normalize("region", res.get("region"))
            subculture = normalize("subculture", res.get("subculture"))
            genre = normalize("genre", res.get("genre"))
            conf = float(res.get("confidence", 0.0))

            # å†™å…¥æ•°æ®åº“
            sem.execute("""
                INSERT OR REPLACE INTO music_semantic (
                    file_id, title, artist, album, mood, energy, scene,
                    region, subculture, genre, confidence, model
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (str(s['id']), s['title'], s['artist'], s['album'],
                  mood, energy, scene, region, subculture, genre,
                  conf, MODEL))
            sem.commit()
            success += 1

            # è¯¦ç»†æ—¥å¿—å†™å…¥
            logger.debug(
                f"[{idx}/{total}] ğŸ§ {meta} | "
                f"ğŸ§  Raw LLM Content: {raw_content[:200]}... | "
                f"ğŸ§¾ Stored: {mood}|{energy}|{region}|{subculture}|{genre} (Conf: {conf}) | "
                f"âœ… Done in {elapsed:.2f}s"
            )

            # æ§åˆ¶å°è¿›åº¦æ¡
            avg_time = (time.time() - start_time) / success
            eta = avg_time * (total - idx)
            disp_meta = (meta[:30] + '..') if len(meta) > 30 else meta
            sys.stdout.write(f"\rè¿›åº¦:[{idx}/{total}] ETA:{format_time(eta)} | {disp_meta:<35}")
            sys.stdout.flush()

        except Exception as e:
            logger.error(f"âŒ FAILED: {meta} | Error: {str(e)}")
            time.sleep(API_CONFIG["retry_delay"])

    logger.info(f"ğŸ Finished. Processed {success}/{total} songs in {format_time(time.time()-start_time)}")


if __name__ == "__main__":
    main()
